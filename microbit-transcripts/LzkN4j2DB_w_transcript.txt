micro:bit LIVE 2021 | Frequency Recognition on the micro:bit V2
https://www.youtube.com/watch?v="LzkN4j2DB_w
okay hello everybody and welcome to this talk on exploring the scope and educational value of frequency recognition on the micro bit v2 and as um very kindly mentioned for me that's actually just a huge mouthful to try and make my dissertation sound more interesting um so in simple terms we're basically looking at can you recognize musical notes on a micro bit v2 and how sound as a whole can enhance learning with the micro bit okay so how did this work kind of come about i'll give you a bit of a background first um this work was done as part of my master's course in computer science at lancaster university and during the course you want to take a 10-week work placement um and i did mine with of course the amazing microgrid foundation who are great partners with the uni and during that time on placement um i was looking at ways to improve the current sound capability of the micro bit especially sound output um and that's kind of a theme that i took into my university dissertation which was about 10 weeks and that's the kind of work i'd be focusing on today and see where that kind of led me for my dissertation okay so the first question is what kind of why bother investigate sound at all really and for this i can borrow really from the reasons for incorporating a microphone speaker into the v2 in the first place and that's that sound vastly expands the range of applications the v2 can be used for and the academic subjects it can be used to enhance and as we've seen throughout the event today there's loads and loads of things that you won't even think about it can be useful um you know sound is interactive it's tangible it's engaging and most importantly it's it's fun and children are just really naturally drawn to it and they just want to play with the sound as soon as they know it's in there um so for any teachers listening i apologize uh but for most the microbit is obviously an educational device so kind of what are the benefits of sound in this area what can it what can it bring and these are the things i kind of proposed and these are things that will look at the end were these achieved in this kind of project um the main advantage of sound is that it can break down these kind of traditionally black box concepts or a concept that you can't physically represent or see so internet messaging is a good example of this you can't see them you can't smell them because they're invisible things right and you can use center sound to represent these in a much more tangible and understandable format and you can use that to kind of well the term we're using as a stepping stone to these more advanced kind of radio features um by learning the basics in a more tangible real world example using sound additionally um hopefully this is going to help him you know to go some way to improve accessibility of the device especially for people with visual impairments um as part of that kind of ongoing process okay so these are all the kind of great features of sound and we've got the hardware on the v2 with the intel microphone speaker the question is how do we kind of really squeeze out as much value as we can from from these new features and how do we extend them um and then to frequency recognition so after brainstorming a bunch of options to kind of how do we expand on these uh sound features with the micro bit i tried to look at frequency recognition because it carried on quite nicely from my placement work which was making sound and also it sounded the most fun to annoy my housemates with which i'm sure they were very grateful for um so yeah like i said the microwave is quite good at making sounds at the minute as i'm sure any of you have played with it will know but um you know it doesn't really do much in the way of recognizing sound and that kind of feels like kind of a natural way to complete that circle recognize sound produce and recognize and produce it so one of the main questions i was kind of looking at and answering in this work uh firstly is frequency recognition even possible on the microwave v2 and spreader alert and good for me that it is or else this would be a much shorter presentation um we also ask you know how accurate can that be um is it just there is a sound playing or can you narrow it down to a specific note what types of sound can we so obviously a sound play from the micro bits input speaker will sound different to a sound played on a phone or a computer or even a real instrument and finally of course this even if it does work is it actually any good in an educational context okay before i get you guys talking um a brief just briefly what actually is frequency recognition well it's as simple as the kind of words suggest it's getting what the microphone hears and turning it into a frequency which we measure in hertz and that can be translated into a letter now if you want to so you can see there on that little table the lesser notes which you're perhaps more used to cbea and they all all have this hurts which is actually related to the wavelength but that's too technical boring so basically it's listen to the microphone and see what notes playing okay so now you know a little bit about frequency recognition um and before i reveal some of the ideas that we kind of envision this would be useful for i'd like you all to take a minute the guys in the audience and see if you guys can come up with something uh which or a project or something fun which might use frequency recognition and i'd like to see what kind of ideas you've got before we really get into it so i'll give you one to kick off uh perhaps a guitar tuner there's one that we came up with so you could imagine if your micro bit could determine different notes you could strap it onto the top of your guitar and see when it was in tune and make your own guitar tuner so i'll give you guys a couple of minutes um just to try and pop your ideas in chat and we'll have a look at what you guys come up with and you can do the work for me that'd be better so yeah i'll give you guys a couple of minutes and i can drink some water get my demo ready for later so okay awesome okay let's have a look you guys have come up with you can see the track harmonized with singers yeah yeah that's a nice nice one i'm sure it would be much better use on somebody who could sing unlike me i did consider this but i thought yeah meet me singing not something i want to subject you guys to um but it makes me think of that there was definitely a game right it's like sing star or something and you have to sing along to the notes yeah i thought that'd be quite cool if you could make your own one of them right um graphic equalizers yeah yeah yeah definitely that would be cool when they can imagine the kind of dancing along carlos yeah data transmission uh we we did something similar with the fireflies project right with radio you could kind of represent that as with sound yeah oh yeah and uh yeah using as a trigger so we'll get on to the different ways you could detect a frequency a little bit later so all excellent ideas thank you for that guys and i shall add them to my word cloud which you can see um i've slowly been building as people people um have given given feedback so yeah you've got a lot of these kind of communication and networking radio morse code you could use to represent these things um you've got physics physics stuff doppler effects and the speed of sound that kind of stuff um yeah music singing pitch detection um measuring the kind of uh yeah music reactive stuff or automatic metronomes that sync to your beat so yeah it's all so it's okay if nothing's coming to you straight away it'll be one of them things that you kind of think about on overnight and you'll think of some things at 3am and have to rush up and write them down for me okay so thanks for that guys um and we'll carry on what does um what so what is the system that kind of can do all this look like and these are the objectives that i set um there's kind of three main categories obviously we've got the technical challenge of can we actually detect accurately within about a hertz probably if you wanted to do um kind of instrument tuners now can we do that you've got obviously the educational value which we've mentioned you know it's able to deliver new areas of the curriculum and are we able to make currently difficult concepts easier because if it makes them harder there's no point and obviously in order to be successful we've got to consider the usability and we've got to consider the audience it needs to be engaging it needs to be appealing and easy to use for our kind of target audience of late primary school early early high school so just before we jump in any further we should probably start to consider why the microbit's so good for this project um there's kind of obviously two major competitors with arduino and raspberry um but despite these companies making a huge range of products the microwave v2 stands out as the clear winner for a number of reasons firstly it's got a huge existing presence in schools already um with over 20 million children already learning with the micro bit for the price point of 10 to 15 pounds the hardware is is better if or competitive at least with um the rifles and perhaps most importantly for this work none of the other competitors have a board which has a built-in microphone and speaker so you have to have extra components wires soldering whether the microphone is just kind of ready to go out of the box uh on the software side the micro it's got it covered as well so obviously it can be programmed in anything from c plus plus to python to make code so it really is um quite a good package for this piece of work okay so how does it work i i won't bore you too much with this if anyone's interested in the kind of nitty-gritty bits then feel free to reach out to me after but for the most part i imagine this will be very boring for you also here's the here's a high level idea basically we take in time domain information from the microphone which is this red squiggly line you can see and we use a process called fft or the fast fourier transform algorithm to convert that into a frequency space so what we do is we take that wiggly red white line and we want to split it into its sine pure sine wave components so there might be just one if it's quite simple if you're just playing one note if you're playing more than one note like a chord on a piano it'll obviously be more and this algorithm basically splits out um this graph this blue graph which shows you the peaks and frequency and they are the kind of frequencies that it's detecting so what does this what does this look like um and what does this look like for different note types so sine waves are quite easy to detect i'll show you what they look like as i imagine nobody will have any difficulty recognizing which frequency is detected there that one very obvious large peak on the graph unfortunately the microgrip primarily uses square waves and square waves when you put them through an fft loop something more like that now 10 points if anyone can tell me which of them spikes is actually the frequency we wanted i'll give you i'll give you a second 10 points anybody no it's um it's a trick question it's none of them it's actually the distance in between the spikes that we want to find out so this is another challenge um we're looking into this area because not quite as simple as the sine waves and obviously this is in the perfect world so if we look over into the real world now what do we actually get from that blue fft graph when we play a note to it from the mic a bit yeah it's starting to look less pretty we have these kind of double spikes now they're kind of all out of order there's different sizes and this is kind of the core problem that we kind of have to overcome with this dissertation especially if you start to play more than one note at once um because it starts to look more like that so really the main cut time was spent taking that graph from that information and trying to produce these component frequencies um that we want to detect okay so what did this develop system actually end up being able to do so as you somebody mentioned uh with the triggers yeah we've got the event here so we said if you hear an a or an e then do something you know um and then we have this idea of primary and secondary notes and basically they're just determined on volume so primary note is the loudest note that they can hear and the secondary one is if you're playing another note at the same time the second loudest one so if you were playing four notes it would pick the top two in terms of loudness if you weren't playing if you just playing one you just have a primary output here so yeah we were able to get the closest primary note that's the letter so abcd and actually get the primary frequency which was in hertz so you could you know make it easier and use the notes or you could dive a bit deeper if you wanted and actually start getting into two hertz and wavelengths okay so once the system was all up and running how do we evaluate it so there's three stages to this evaluation i i did um first it was obviously the internal testing which is all that kind of boring quantitative stuff you know how far can i recognize what range of notes can it recognize and how well does it technically perform and then you've got the qualitative kind of stuff which was really looking can it achieve them educational things we highlighted at the start of this presentation does it allow you to create programs which come kind of kind of break down them black box concepts kind of enhance the learning experience so here we go what we've all been waiting for the results was this dissertation actually worth it well firstly how accurate was the recognition and can we detect them from phones which use the sine waves and from other micro bits which is their more difficult square wave looking ones and the result is thankfully yes we can and actually with surprising accuracy so across the board here we can see there was an average distance between what we actually expected so the true note we played to what the micro bit said it was hearing what it detected was just 0.7 hertz out and for scale you can see between each letter note so the difference between an a and a b is something around 30 to 50 hertz so being 0.7 of a hertz is pretty close and it's in that kind of ballpark of being able to do instrument tuners and that kind of stuff uh so what distance will be able to recognize these notes from i'm using this fft using a micro bit speaker which obviously isn't super loud we were able to get um notes recognized from 90 centimeters for all of them and some were a little bit further but all of them were at 90 centimeters so it's quite a long recognition distance of just under a meter and obviously if you use a phone or a bigger speaker you could kind of pump this distance up but that was just using the inbuilt speaker an inbuilt microphone of two different micro bits did it work on live instruments um well again the live instruments are a tricky beast if you look in this little diagram at the bottom this is a true c play from a tuning fork and this is a c played in the clarinet and a trumpet and what them waves look like as you see there because they're quite messy and difficult so surprisingly this did manage to work and although we had a few problems with what's called concept pitch so for example a trumpet um if you play ac will actually come out as a b-flat because that's how they're tuned so we'd have to make a slight adjustment for what instrument you were playing but what the adjustments made it was certainly plausible that um this detection will work with real instruments we tried it with a trumpet a saxophone and a flute and they all worked i'm just somewhat slightly off with this tuning pitch yeah certainly reasonable to say that it would work with um with real instruments too and not just electronic sounds for everyone that loves some numbers here you go uh the develop prototype system was able to theoretically recognize frequencies from zero to five thousand five hundred and twelve hertz but you probably don't really wanna be going over two thousand for a human anyway um and the maximum error was about 5.38 hertz so towards the top and bottom end of them scales it's not quite as accurate but we didn't really test um the whole range uh it takes 10 to 11 milliseconds to do that processing so from the time it says right go listen 10 11 milliseconds before you get a result so really pretty quick um so certainly fast enough to do close to real real-time processing with this okay so technically it kind of works what did what do people think of it though does it work in an academic system well here's what they have to say um i said it was kind of accurate beyond what they thought it was going to be um the academics thought that they really liked the possibility of the micro bit which is what i was kind of saying with that versus competitive thing right it's really good because it's just a whole package you don't have to worry about extra wires extra components extra bits they thought enable difficult concepts to be presented in a way that's much easier to understand so that's great um they thought the features were engaging and fun uh that it widened the appeal of the micro bits of people who perhaps wouldn't otherwise be interested so you think you can hear people who perhaps are interested in music uh who might not traditionally be interested in computing and this is kind of a routine for them and they concluded it kind of did open up a lot of new projects lessons and topics that could now be explored that previously couldn't so things like the doppler effect things like that uh the second one uh the second second trial was with the macrobot team themselves so unlike the first one which was a blind test so they really got to see kind of their first impressions of it obviously the microbit team um were collaborating on me with this so they knew they knew all about the squeaky horrible sounds it was making um but yeah they were also impressed with the kind of accuracy of the detection and the distance it could be recognized from um they thought it was useful for teaching these black box concepts and then that would allow a deeper understanding uh to be gained by by the kids uh this is much more appealing than radios specifically and it's quite easy to draw parallels between sound and radio which we'll see in a few demos in just a short while they said it was more engaging appeals a lot a wider audience and it improves accessibility um anyone can join in by singing humming um and also on the visual impairments you can improve then but i won't demonstrate that to you now as i previously mentioned again yeah because they managed to identify a lot of use cases across a broad range of subjects a lot of which you saw in that sound in that word cloud just just previous okay so what's the conclusion what's this worth doing well we found sound recognition is possible and it's accurate within about one hertz recognition can be done with sine waves and from square waves like the microbial speaker and also from real instruments in terms of having educational value well yes the new features allow the test users to create new systems that widen the range of topics that could be taught with the microbit the teachers concluded it made teaching currently difficult black bot concepts easier by making the method of teaching more transparent a more tangible physical things like the internet messaging and it was agreed the features were engaging and fun and improved accessibility so to round all that up what did we learn well we learned accurate frequency detection of multiple key frequencies from a range of devices and instruments as possible on the microwave v2 and also that there is educational value and extending the sound features v2 which are all the benefits we mentioned at start and frequency recognition is one suitable way in which to do this and obviously i'm sure there'll be many more as well so there's still plenty of work to do on this um the ui which we'll see in a minute um was flag for improvement uh we could increase the range of letter notes that can be shown so currently we're only able to um detect the middle octaves so uh c 4 and up the number of concurrent notes so we have that primary and secondary idea is obviously limited to two and it'd be better if you could kind of recognize three four or five notes at the same time if you're thinking about doing chords on a piano um extra statistics would be good so if anyone's used the radio you'll know you can get statistics from it like the signal strength which would obviously be volume in our case um and the last thing to consider although the teachers who tested it didn't reflect this particularly as an issue um lots of sound in the classroom especially high pitched ones could be quite annoying um i know how do we kind of go about mitigating that if it does turn out to be a problem okay that's enough waffling on uh let's get into the fun stuff so i'll give you give you some quick demos here of the system that i've been what we're working on about and you can see how it actually works and what it looks like so we're going to try the live demo fingers crossed this will always go well won't it to start with so can somebody give me a frequency between kind of 100 and 550 hertz and i'll show you a little bit what this looks like which you can just pop that in the chat 240 excellent choice so i'm just going to go on a tone generation on my phone type in 240 hertz so you can see that's now making that sound if we look i'm not sure how well you're going to be able to see this let me try and make it bigger for you so here we have this format it's a little bit confusing but here we go primary note secondary note this x will tell us if it's a letter that says heard and x means no letter and this number is what we're really looking at that's the frequency that it's picking up so we're only playing one frequency so we're just interested in the primary notes let's see if it will recognize the 240 when we start playing it [Laughter] not bad 241 get a bit of rounding error we can take that so i'll show you now you know we can play c and i'll just go up through the scale that's a d an e f g there's an a and finally a b so that's that's the kind of raw output that we can get from from the micro bit um and thank goodness that worked okay so now i'll show you that's kind of like i say the raw bare bones kind of functionality that this system provides but you know what can i actually do how do you use that so i've given some uh i've come up with some quick demos to show how that could be used and these are the card demos i gave in them user trials um to get the feedback on it so the first one we have here is um http request response so this is if you were teaching about web development or something like that how do you physically demonstrate an internet message right uh really some sorry it's quite a basic thing but how do you teach that right you can't see it you can't feel it well how this is one way you could do it with sound so this demo shows um signal strength so these two micro bits are bleeping to each other one plays an a one plays an e and oh it's just a simple super simple logic if you hear an e playing a the other one if i hear an a plain e and they'll just talk to each other and basically i'll move them apart and you'll see how that signal strength or volume in our case diminishes and they start to get weaker and eventually they'll stop talking to each other and this is how we can kind of represent communication the sound form so i apologize if anyone's got any dogs because there's some going to be some beepy sounds [Music] now you can see they've stopped so the volume wasn't loud enough to be detected anymore and hence the message has failed so just one example um here's another one a good one the noise how does noise affect the signal so obviously in the real world we get interference from other things that's why your you know tv remote doesn't work or something and you can actually represent noise in this format with real-life noise so again these two markers are just talking to each other and you can see when i make a lot of noise by tapping the table uh then the record then the messages will fail just like a packet would fail in a network if there was too much noise there we go um okay this this one is just showing you so we did with a phone then in the live demo so this is a micro bit actually making them sounds which it can already do so the one with the black cables making the sounds and all the white cable is actually you running this system that i built and it's going to display on the screen which nobody thinks it's hearing the note displayed on the one with the black cable is um what we're playing so hopefully they should match hey and there we go so that's what it looks like micro bit to micro bit and obviously that's a super simple demo but it just shows the functionality of okay there's one last um one i'll show you and then we'll go through some questions and that is some more code [Music] here we go so it's a little bit slow but here's actually one playing morse code the one with the blackwise playing the morse code out and the one with the white wire is just blending um the letters that i hears so it's going to play abcdef um and hopefully the one on the left will pick that up so this is representing communication through sound [Music] [Laughter] [Music] [Laughter] me [Laughter] [Music] [Laughter] [Music] [Music] and there we go i think the sound was a little bit out of sync on that one but um yeah you can see the right one was sending them little bps and the left one successfully recognized that morse code and then it converted that into the letter okay so that's um that's it from me i'll stop boring you now um so uh yeah here's any any kind of questions fire away uh again if you're interested in stuff just uh find me an email it's absolutely no problem there you go thank you very much hey joshua amazing job thank you so so much for that and especially the demos i really enjoyed actually seeing it happen uh which is exciting uh we have a question from tanya that said that you mentioned this as part of your dissertation is a copy available for general consumption uh yeah yeah i can definitely get that to you uh it's not published anywhere at the minute but um yeah if you pop me an email on the screen there yeah i can send that over to you if you're being honest it's a big read though i'll warn you for that i think it's 70 plus thousand words that's a good that's a good associate dissertation martinez asking will this become an extension in make code well there is a lot of work that's kind of close to doing it i'll i'll show you the the ui is built in make code same as asking if it's like it's available in github yeah i think the work is available github i'll check with you uh check with that and and get back to you on that uh there we go so you can see i'm slowly loading my internet's not brilliant here and poor else here we go um there we go it's waking up so yeah i have built them in my code so here's a box you can see um which i've got the kind of event blocks and they're kind of on hearing blocks and stuff um it does use a kind of uh special version of the maker run time now so um i'll look into how you guys can kind of play with it yourselves if that's something you're interested in perfect and you could actually just uh even post it in the event chat if you do find it if this chat closes down um we are at time and we are now moving into our next sessions so once again thank you joshua so much and just also you should be very proud of the work that you're doing um especially for your masters and i don't think it needs to sound any more exciting than it is um thank you so much and everybody else uh we will move on if you go back to your sessions tab we have sessions coming interactive sessions once again um so let's get to it thank you all right thanks so much thanks guys